# Machine-learning Paper review (20200819 ~ )  
- Machine learning Paper review and code implementation in weekly Sclab seminar  

## Paper 1. Turing, Alan Mathison. "On computable numbers, with an application to the Entscheidungsproblem." J. of Math 58.345-363 (1936): 5.
[[Presentation]](https://github.com/OH-Seoyoung/Machine-learning_Paper_review/blob/master/Paper.1_Turing_Machine/20200929_Paper1_Turing_Machine.pdf)  

## Paper 2. Turing, Alan M. "Computing machinery and intelligence." Parsing the turing test. Springer, Dordrecht, 2009. 23-65.  
[[Presentation]](https://github.com/OH-Seoyoung/Machine-learning_Paper_review/blob/master/Paper.2_Imitation_Game/20201006_Paper2_Imitation_game.pdf)  

## Paper 3. Rumelhart, David E., Geoffrey E. Hinton, and Ronald J. Williams. "Learning representations by back-propagating errors." nature 323.6088 (1986): 533-536.  
[[Presentation]](https://github.com/OH-Seoyoung/Machine-learning_Paper_review/blob/master/Paper.3_Back-Propagation/20201110_Paper3_Back-Propagation.pdf) | [[Code]](https://github.com/OH-Seoyoung/Machine-learning_Paper_review/blob/master/Paper.3_Back-Propagation/Simple_implementation_of_back-propagation.ipynb)  

## Paper 4. LeCun, Yann, et al. "Gradient-based learning applied to document recognition." Proceedings of the IEEE 86.11 (1998): 2278-2324.
[[Presentation]](https://github.com/OH-Seoyoung/Machine-learning_Paper_review/blob/master/Paper.4_Convolutional_Neural_Network/20201201_Paper4_Convolutional_Neural_Network.pdf) | [[Code]](https://github.com/OH-Seoyoung/Machine-learning_Paper_review/blob/master/Paper.4_Convolutional_Neural_Network/Simple_implementation_of_CNN.ipynb)  

## Paper 5. Hinton, Geoffrey E., and Ruslan R. Salakhutdinov. "Reducing the dimensionality of data with neural networks." science 313.5786 (2006): 504-507.  
[[Presentation]](https://github.com/OH-Seoyoung/Machine-learning_Paper_review/blob/master/Paper.5_Dimensionality_Reduction_DBN/Paper.5_Dimensionality_Reduction_DBN.pdf)  

## Book 1. Pattern Recognition & Machine Learning, Bishop
> 1. Polynomial Curve Fitting, Error function (RMS), Model Selection, Regularization | [[Presentation]](https://github.com/OH-Seoyoung/Machine-learning_Paper_review/tree/master/Book.1_Pattern_Recognition_and_Machine_Learning%2C_Bishop)  
> 2. Probability Theory - Bayesian probabilities, Parameter Estimation, Cross Validation, Information criteria - AIC | [[Presentation]](https://github.com/OH-Seoyoung/Machine-learning_Paper_review/blob/master/Book.1_Pattern_Recognition_and_Machine_Learning%2C_Bishop/20200901_PRML.pdf)  
> 3. The curse of dimensionality, Decision Theory, Minimizing the misclassification rate | [[Presentation]](https://github.com/OH-Seoyoung/Machine-learning_Paper_review/blob/master/Book.1_Pattern_Recognition_and_Machine_Learning%2C_Bishop/20200908_PRML.pdf)  
> 4. Minimizing the expected loss, Inference and decision, Generative and Disciriminative models, Loss function for regression | [[Presentation]](https://github.com/OH-Seoyoung/Machine-learning_Paper_review/blob/master/Book.1_Pattern_Recognition_and_Machine_Learning%2C_Bishop/20200915_PRML.pdf)  
> 5. Information theory, Entropy, Gaussian Distribution | [[Presentation]](https://github.com/OH-Seoyoung/Machine-learning_Paper_review/blob/master/Book.1_Pattern_Recognition_and_Machine_Learning%2C_Bishop/20200922_PRML.pdf)  
